{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_ZERO_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGwEyFyQUBvTwvBjdodL1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukasztracz195/MNIST_ZERO_GAN/blob/main/MNIST_ALL_DIGITS_GAN_CHANGED_PARAMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKVLgcQ7of5G"
      },
      "source": [
        "#Implementacja sieci GAN do nauczenia się jak wygląda liczba 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nidgsnwou0G"
      },
      "source": [
        "##Import bibliotek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvfboNizy-2W"
      },
      "source": [
        "###Ustawienie odpowiedniej biblioteki TensoreFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPR7bSbnvnIK",
        "outputId": "acc2835b-3656-4cb4-a784-de9b60597a75"
      },
      "source": [
        "# To determine which version you're using:\r\n",
        "!pip show tensorflow\r\n",
        "\r\n",
        "# For a specific version:\r\n",
        "!pip install tensorflow==1.9"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.9.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorboard, numpy, grpcio, absl-py, gast, six, termcolor, setuptools, wheel, astor, protobuf\n",
            "Required-by: Keras, fancyimpute\n",
            "Requirement already satisfied: tensorflow==1.9 in /usr/local/lib/python3.6/dist-packages (1.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (1.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (1.34.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (0.36.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (39.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzjax055zJI_"
      },
      "source": [
        "###Instalacja odpowiedniej biblioteki Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC33oThgzMUl",
        "outputId": "e9f56c0c-c847-4ac7-d771-7d59c5c35403"
      },
      "source": [
        "!pip3 install keras==2.0\r\n",
        "!pip3 show keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0) (3.13)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from keras==2.0) (1.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (1.34.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (0.36.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (39.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (1.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras==2.0) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow->keras==2.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow->keras==2.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow->keras==2.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow->keras==2.0) (3.4.0)\n",
            "Name: Keras\n",
            "Version: 2.0.0\n",
            "Summary: Deep Learning for Python\n",
            "Home-page: https://github.com/fchollet/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorflow, six, pyyaml\n",
            "Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VD3IFZgzOOm"
      },
      "source": [
        "###Instalacja odpowiednich zbiorów danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofdYe-PBskUU",
        "outputId": "809c776e-6424-40cb-f1e5-896736100661"
      },
      "source": [
        "%%bash\r\n",
        "pip install python-mnist\r\n",
        "pip install tensorflow-datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-mnist in /usr/local/lib/python3.6/dist-packages (0.7)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (20.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.25.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (3.12.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (4.41.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.1.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets) (39.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYUjNiPoRQx",
        "outputId": "829cbb0f-765c-470d-f0bd-9c77f6f0e361"
      },
      "source": [
        "import numpy as np\r\n",
        "import time\r\n",
        "\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Flatten, Reshape\r\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\r\n",
        "from keras.layers import LeakyReLU, Dropout\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "from keras.optimizers import Adam, RMSprop\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP7hfNWqpp8e"
      },
      "source": [
        "#Implementacja klasy ElapsedTimer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD-GacLkpFx4"
      },
      "source": [
        "class ElapsedTimer(object):\r\n",
        "    def __init__(self):\r\n",
        "        self.start_time = time.time()\r\n",
        "    def elapsed(self,sec):\r\n",
        "        if sec < 60:\r\n",
        "            return str(sec) + \" sec\"\r\n",
        "        elif sec < (60 * 60):\r\n",
        "            return str(sec / 60) + \" min\"\r\n",
        "        else:\r\n",
        "            return str(sec / (60 * 60)) + \" hr\"\r\n",
        "    def elapsed_time(self):\r\n",
        "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_biVu1ibNWQg"
      },
      "source": [
        "##Sieci GAN są trudne do trenowania\r\n",
        "#####Trening GAN polega na znalezieniu równowagi Nasha do gry dla dwóch graczy, która nie jest kooperacyjna. […] Niestety znalezienie równowagi Nasha jest bardzo trudnym problemem. Istnieją algorytmy dla wyspecjalizowanych przypadków, ale nie znamy żadnych możliwych do zastosowania w grze GAN, w której funkcje kosztów są niewypukłe, parametry są ciągłe, a przestrzeń parametrów jest niezwykle wielowymiarowa\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E71MJ6QYOFRW"
      },
      "source": [
        "###Największe problemy sieci GAN:\r\n",
        "#####1. Być może najtrudniejszym problemem jest przypadek, w którym wiele sygnałów wejściowych trafiających do generatora powoduje wygenerowanie tego samego wyjścia.\r\n",
        "\r\n",
        "Nazywa się to „ upadkiem trybu / mode collapse ” i może stanowić jeden z najtrudniejszych problemów podczas uczenia sieci GAN.\r\n",
        "\r\n",
        "\"Mode collapse, znany również jako scenariusz problemu, który pojawia się, gdy generator uczy się mapować kilka różnych wejściowych wartości do tego samego punktu wyjściowego.\"\r\n",
        "\r\n",
        "####2. Nie ma dobrych obiektywnych mierników do oceny, czy GAN działa dobrze podczas treningu. Np. Ocena straty nie jest wystarczająca.\r\n",
        "\r\n",
        "Zamiast tego najlepszym podejściem jest wizualna inspekcja wygenerowanych przykładów i zastosowanie subiektywnej oceny.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIYpYZegMd-9"
      },
      "source": [
        "###Wskazówki znalezione w sieci dotyczące modelowania sieci GAN:\r\n",
        "\r\n",
        "### 1.Normalizuj wejścia do zakresu [-1, 1] i użyj tg na wyjściu generatora.\r\n",
        "### 2.Odwróć etykiety i funkcję utraty podczas szkolenia generatora.\r\n",
        "### 3. Przykładowe liczby losowe Gaussa jako dane wejściowe do generatora.\r\n",
        "### 4. Użyj mini partii wszystkich prawdziwych lub wszystkich fałszywych do obliczania statystyk norm partii.\r\n",
        "### 5. Użyj Leaky ReLU w generatorze i dyskryminatorze.\r\n",
        "### 6. Użyj średniej puli i kroku do próbkowania w dół; użyj ConvTranspose2D i stride do upsamplingu.\r\n",
        "### 7. Użyj wygładzania etykiet w dyskryminatorze z małym przypadkowym szumem.\r\n",
        "### 8. Dodaj losowy szum do etykiet w dyskryminatorze.\r\n",
        "### 9. Używaj architektury DCGAN, chyba że masz dobry powód by używać innej.\r\n",
        "### 10. Utrata 0,0 w dyskryminatorze jest stanem awarii.\r\n",
        "### 11. Jeśli utrata generatora stale się zmniejsza, prawdopodobnie oszukuje dyskryminator obrazami śmieci.\r\n",
        "### 12. Użyj etykiet, jeśli je masz.\r\n",
        "### 13. Dodaj szum do wejść dyskryminatora i zanikaj go w czasie.\r\n",
        "### 14. Użyj 50 procent spadku podczas treningu i generowania.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ_G1aTHoqff"
      },
      "source": [
        "#Implementacja klasy DCGAN\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ-WvXbkokXm"
      },
      "source": [
        "class DCGAN(object):\r\n",
        "    def __init__(self, img_rows=28, img_cols=28, channel=1):\r\n",
        "\r\n",
        "        self.img_rows = img_rows\r\n",
        "        self.img_cols = img_cols\r\n",
        "        self.channel = channel\r\n",
        "        self.D = None   # discriminator\r\n",
        "        self.G = None   # generator\r\n",
        "        self.AM = None  # adversarial model // model przeciwności\r\n",
        "        self.DM = None  # discriminator model // model dyskrymiancji\r\n",
        "\r\n",
        "    # (W−F+2P)/S+1\r\n",
        "    '''\r\n",
        "    W sieciach GAN zaleca się, aby nie używać warstw łączących,\r\n",
        "    a zamiast tego używać kroku w warstwach konwolucyjnych\r\n",
        "    do wykonywania próbkowania w dół w modelu dyskryminatora\r\n",
        "    '''\r\n",
        "    '''\r\n",
        "    ReLU jest zalecany dla generatora, ale nie dla modelu dyskryminatora.\r\n",
        "    Zamiast tego w dyskryminatorze preferowana jest odmiana ReLU,\r\n",
        "    która dopuszcza wartości mniejsze od zera, zwana Leaky ReLU.\r\n",
        "    '''\r\n",
        "    '''\r\n",
        "    W praktyce dyskryminator jest zwykle głębszy\r\n",
        "    i czasami ma więcej filtrów na warstwę niż generator.\r\n",
        "    '''\r\n",
        "    def discriminator(self):\r\n",
        "        if self.D:\r\n",
        "            return self.D\r\n",
        "        self.D = Sequential()\r\n",
        "        depth = 64\r\n",
        "        dropout = 0.4\r\n",
        "        # In: 28 x 28 x 1, depth = 1\r\n",
        "        # Out: 14 x 14 x 1, depth=64\r\n",
        "        input_shape = (self.img_rows, self.img_cols, self.channel)\r\n",
        "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\r\n",
        "            padding='same'))\r\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\r\n",
        "        self.D.add(Dropout(dropout))\r\n",
        "\r\n",
        "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\r\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\r\n",
        "        self.D.add(Dropout(dropout))\r\n",
        "\r\n",
        "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\r\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\r\n",
        "        self.D.add(Dropout(dropout))\r\n",
        "\r\n",
        "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\r\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\r\n",
        "        self.D.add(Dropout(dropout))\r\n",
        "\r\n",
        "        # Out: 1-dim probability\r\n",
        "        self.D.add(Flatten())\r\n",
        "        self.D.add(Dense(1))\r\n",
        "        #Na końcu potrzebujemy wartości[0,1] 0=fake 1=true\r\n",
        "        self.D.add(Activation('sigmoid')) \r\n",
        "        self.D.summary()\r\n",
        "        return self.D\r\n",
        "\r\n",
        "    def generator(self):\r\n",
        "        if self.G:\r\n",
        "            return self.G\r\n",
        "        self.G = Sequential()\r\n",
        "        dropout = 0.4\r\n",
        "        depth = 64+64+64+64\r\n",
        "        dim = 7\r\n",
        "        # In: 100\r\n",
        "        # Out: dim x dim x depth\r\n",
        "        self.G.add(Dense(dim*dim*depth, input_dim=100))\r\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\r\n",
        "        self.G.add(LeakyReLU(alpha=0.2))\r\n",
        "        self.G.add(Reshape((dim, dim, depth)))\r\n",
        "        self.G.add(Dropout(dropout))\r\n",
        "\r\n",
        "        # In: dim x dim x depth\r\n",
        "        # Out: 2*dim x 2*dim x depth/2\r\n",
        "        self.G.add(UpSampling2D())\r\n",
        "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\r\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\r\n",
        "        self.G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "        self.G.add(UpSampling2D())\r\n",
        "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\r\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\r\n",
        "        self.G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\r\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\r\n",
        "        self.G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\r\n",
        "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\r\n",
        "        self.G.add(Activation('tanh'))\r\n",
        "        self.G.summary()\r\n",
        "        return self.G\r\n",
        "\r\n",
        "    def discriminator_model(self):\r\n",
        "        if self.DM:\r\n",
        "            return self.DM\r\n",
        "        optimizer = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "        self.DM = Sequential()\r\n",
        "        self.DM.add(self.discriminator())\r\n",
        "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\r\n",
        "            metrics=['accuracy'])\r\n",
        "        return self.DM\r\n",
        "\r\n",
        "    def adversarial_model(self):\r\n",
        "        if self.AM:\r\n",
        "            return self.AM\r\n",
        "        optimizer = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "        self.AM = Sequential()\r\n",
        "        self.AM.add(self.generator())\r\n",
        "        self.AM.add(self.discriminator())\r\n",
        "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\r\n",
        "            metrics=['accuracy'])\r\n",
        "        return self.AM\r\n",
        "\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwn2TBU6r1Y5"
      },
      "source": [
        "#Implementacja klasy MNIST_DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qldMPir05i"
      },
      "source": [
        "class MNIST_DCGAN(object):\r\n",
        "    def __init__(self):\r\n",
        "        self.img_rows = 28\r\n",
        "        self.img_cols = 28\r\n",
        "        self.channel = 1\r\n",
        "\r\n",
        "        self.x_train = input_data.read_data_sets(\"mnist\",\\\r\n",
        "        \tone_hot=True).train.images\r\n",
        "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\r\n",
        "        \tself.img_cols, 1).astype(np.float32)\r\n",
        "\r\n",
        "        self.DCGAN = DCGAN()\r\n",
        "        self.discriminator =  self.DCGAN.discriminator_model()\r\n",
        "        self.adversarial = self.DCGAN.adversarial_model()\r\n",
        "        self.generator = self.DCGAN.generator()\r\n",
        "\r\n",
        "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\r\n",
        "        noise_input = None\r\n",
        "        if save_interval>0:\r\n",
        "            noise_input = np.random.normal(0.0, 0.2, size=[16, 100])\r\n",
        "        for i in range(train_steps):\r\n",
        "            images_train = self.x_train[np.random.randint(0,\r\n",
        "                self.x_train.shape[0], size=batch_size), :, :, :]\r\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\r\n",
        "            images_fake = self.generator.predict(noise)\r\n",
        "            x = np.concatenate((images_train, images_fake))\r\n",
        "            y = np.ones([2*batch_size, 1])\r\n",
        "            y[batch_size:, :] = 0\r\n",
        "            d_loss = self.discriminator.train_on_batch(x, y)\r\n",
        "\r\n",
        "            y = np.ones([batch_size, 1])\r\n",
        "            noise = np.random.normal(0.0, 0.2, size=[batch_size, 100])\r\n",
        "            a_loss = self.adversarial.train_on_batch(noise, y)\r\n",
        "            log_mesg = \"%d: [Discriminator loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\r\n",
        "            log_mesg = \"%s  [Generator loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\r\n",
        "            print(log_mesg)\r\n",
        "            if save_interval>0:\r\n",
        "                if (i+1)%save_interval==0:\r\n",
        "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\r\n",
        "                        noise=noise_input, step=(i+1))\r\n",
        "\r\n",
        "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\r\n",
        "        filename = 'mnist.png'\r\n",
        "        if fake:\r\n",
        "            if noise is None:\r\n",
        "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\r\n",
        "            else:\r\n",
        "                filename = \"mnist_%d.png\" % step\r\n",
        "            images = self.generator.predict(noise)\r\n",
        "        else:\r\n",
        "            i = np.random.randint(0, self.x_train.shape[0], samples)\r\n",
        "            images = self.x_train[i, :, :, :]\r\n",
        "\r\n",
        "        plt.figure(figsize=(10,10))\r\n",
        "        for i in range(images.shape[0]):\r\n",
        "            plt.subplot(4, 4, i+1)\r\n",
        "            image = images[i, :, :, :]\r\n",
        "            image = np.reshape(image, [self.img_rows, self.img_cols])\r\n",
        "            plt.imshow(image, cmap='gray')\r\n",
        "            plt.axis('off')\r\n",
        "        plt.tight_layout()\r\n",
        "        if save2file:\r\n",
        "            plt.savefig(filename)\r\n",
        "            plt.close('all')\r\n",
        "        else:\r\n",
        "            plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP4veBInq6bT"
      },
      "source": [
        "#Uruchomienie działania GANA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UowfKOlSq-vR",
        "outputId": "26ad2d6b-f9c0-4c57-ecca-a5ce0375b016"
      },
      "source": [
        "\r\n",
        "mnist_dcgan = MNIST_DCGAN()\r\n",
        "timer = ElapsedTimer()\r\n",
        "mnist_dcgan.train(train_steps=100, batch_size=256, save_interval=500)\r\n",
        "timer.elapsed_time()\r\n",
        "mnist_dcgan.plot_images(fake=True)\r\n",
        "mnist_dcgan.plot_images(fake=False, save2file=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 8193      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,311,553.0\n",
            "Trainable params: 4,311,553.0\n",
            "Non-trainable params: 0.0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,394,241.0\n",
            "Trainable params: 2,368,705.0\n",
            "Non-trainable params: 25,536.0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "0: [Discriminator loss: 0.694946, acc: 0.462891]  [Generator loss: 0.533288, acc: 1.000000]\n",
            "1: [Discriminator loss: 0.636171, acc: 0.500000]  [Generator loss: 0.197985, acc: 1.000000]\n",
            "2: [Discriminator loss: 0.625789, acc: 0.500000]  [Generator loss: 0.077352, acc: 1.000000]\n",
            "3: [Discriminator loss: 0.618322, acc: 0.500000]  [Generator loss: 0.052299, acc: 1.000000]\n",
            "4: [Discriminator loss: 0.541301, acc: 0.500000]  [Generator loss: 0.045493, acc: 1.000000]\n",
            "5: [Discriminator loss: 0.482828, acc: 0.500000]  [Generator loss: 0.027975, acc: 1.000000]\n",
            "6: [Discriminator loss: 0.512546, acc: 0.500000]  [Generator loss: 0.011450, acc: 1.000000]\n",
            "7: [Discriminator loss: 0.531030, acc: 0.500000]  [Generator loss: 0.003627, acc: 1.000000]\n",
            "8: [Discriminator loss: 0.469902, acc: 0.500000]  [Generator loss: 0.000905, acc: 1.000000]\n",
            "9: [Discriminator loss: 0.369785, acc: 0.556641]  [Generator loss: 0.000144, acc: 1.000000]\n",
            "10: [Discriminator loss: 0.273558, acc: 1.000000]  [Generator loss: 0.000013, acc: 1.000000]\n",
            "11: [Discriminator loss: 0.189785, acc: 1.000000]  [Generator loss: 0.000008, acc: 1.000000]\n",
            "12: [Discriminator loss: 0.116439, acc: 1.000000]  [Generator loss: 0.000018, acc: 1.000000]\n",
            "13: [Discriminator loss: 0.058486, acc: 1.000000]  [Generator loss: 0.000001, acc: 1.000000]\n",
            "14: [Discriminator loss: 0.022560, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "15: [Discriminator loss: 0.006578, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "16: [Discriminator loss: 0.001567, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "17: [Discriminator loss: 0.000329, acc: 1.000000]  [Generator loss: 0.000013, acc: 1.000000]\n",
            "18: [Discriminator loss: 0.000062, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "19: [Discriminator loss: 0.000031, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "20: [Discriminator loss: 0.000003, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "21: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "22: [Discriminator loss: 0.000006, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "23: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "24: [Discriminator loss: 0.000001, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "25: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "26: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "27: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "28: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "29: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "30: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "31: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "32: [Discriminator loss: 0.000000, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "33: [Discriminator loss: 0.000295, acc: 1.000000]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "34: [Discriminator loss: 0.047840, acc: 0.994141]  [Generator loss: 0.037293, acc: 0.996094]\n",
            "35: [Discriminator loss: 0.100746, acc: 0.990234]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "36: [Discriminator loss: 0.161475, acc: 0.980469]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "37: [Discriminator loss: 0.540653, acc: 0.953125]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "38: [Discriminator loss: 1.114004, acc: 0.873047]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "39: [Discriminator loss: 2.469735, acc: 0.771484]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "40: [Discriminator loss: 3.205864, acc: 0.689453]  [Generator loss: 0.000000, acc: 1.000000]\n",
            "41: [Discriminator loss: 4.048798, acc: 0.609375]  [Generator loss: 0.000003, acc: 1.000000]\n",
            "42: [Discriminator loss: 3.639509, acc: 0.587891]  [Generator loss: 0.000370, acc: 1.000000]\n",
            "43: [Discriminator loss: 2.005815, acc: 0.562500]  [Generator loss: 0.070732, acc: 0.996094]\n",
            "44: [Discriminator loss: 0.749058, acc: 0.646484]  [Generator loss: 0.991323, acc: 0.136719]\n",
            "45: [Discriminator loss: 0.394653, acc: 0.925781]  [Generator loss: 2.651278, acc: 0.000000]\n",
            "46: [Discriminator loss: 0.393610, acc: 0.800781]  [Generator loss: 3.781732, acc: 0.000000]\n",
            "47: [Discriminator loss: 0.456865, acc: 0.527344]  [Generator loss: 3.704170, acc: 0.000000]\n",
            "48: [Discriminator loss: 0.476146, acc: 0.509766]  [Generator loss: 2.655380, acc: 0.000000]\n",
            "49: [Discriminator loss: 0.431746, acc: 0.529297]  [Generator loss: 1.469652, acc: 0.000000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVJ5SI0rFCz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}